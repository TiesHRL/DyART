{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 31,
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
   "metadata": {},
   "outputs": [],
   "source": [
    "import ARXT\n",
<<<<<<< HEAD
    "from ARXT import hit_rate\n",
    "import Data_gen\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import bayesian_changepoint_detection.bayesian_models as bayes_models\n",
    "from bayesian_changepoint_detection.hazard_functions import constant_hazard\n",
    "import bayesian_changepoint_detection.online_likelihoods as online_ll\n",
    "import time \n",
    "from numpy.linalg import lstsq\n",
    "\n",
    "\n",
=======
    "import time\n",
    "import bayesian_changepoint_detection.bayesian_models as bayes_models\n",
    "from bayesian_changepoint_detection.hazard_functions import constant_hazard\n",
    "import bayesian_changepoint_detection.online_likelihoods as online_ll\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from ARXT import hit_rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
    "def get_data(differencing = False):\n",
    "\n",
    "    # tickers = [\"^GSPC\", \"^IXIC\", \"^DJI\",\"JPYUSD=X\", \"^VIX\", \"GBPUSD=X\", \"EURUSD=X] # , \"GBPUSD=X\", \"EURUSD=X\",\n",
    "    # data = Data_gen.collect_data(tickers)\n",
    "    data = pd.read_csv(\"../Data/fin_data.csv\")\n",
    "    # data.to_csv(\"Data/fin_data.csv\")\n",
    "    data.index = data[\"Date\"]\n",
    "    data = data.drop([\"Date\"], axis=1)\n",
    "    data.columns = range(data.shape[1])\n",
<<<<<<< HEAD
    "    if differencing:\n",
    "        data = data.diff()\n",
    "        data = data.iloc[1:,:]\n",
    "\n",
    "    return(data)\n",
    "\n",
    "def train_run_tree(data, p, max_depth, min_size, max_weight, splt):\n",
    "    p, max_depth, min_size =  int(round(p)), int(round(max_depth)), int(round(min_size))\n",
    "    d_val_cumsum, valid_prediction_cumsum, tree_list = ARXT.ARXT_time_series_pred(data=data, p=p, preprocessing_method='normalization', max_depth=max_depth, min_size=min_size, max_weight=max_weight, splt=splt)\n",
    "    hit_rate_sample = hit_rate(d_val_cumsum, valid_prediction_cumsum)\n",
    "\n",
    "    rmse_sample = (sqrt(mean_squared_error(d_val_cumsum, valid_prediction_cumsum)))\n",
    "\n",
    "    return d_val_cumsum, valid_prediction_cumsum, tree_list, hit_rate_sample, rmse_sample\n",
    "DATA = get_data(differencing=True)\n",
    "\n",
    "def objective_function(p, max_depth, min_size, max_weight, start, fin, splt):\n",
    "    # Set up and train the ART model using the hyperparameters\n",
    "    p, max_depth, min_size, max_weight =  round(p), round(max_depth), round(min_size), round(max_weight)\n",
    "    d_val_cumsum, valid_prediction_cumsum, _, hit_rate_sample, rmse_sample = train_run_tree(DATA[start:fin], p, max_depth, min_size, max_weight, splt=splt)\n",
    "\n",
    "    performance = hit_rate_sample * 2 - rmse_sample * 0.5\n",
    "    return performance\n",
    "def optimizer(pbounds, start, fin, splt, init_points=10, n_iter=30):\n",
    "    optimizer = BayesianOptimization(f= lambda p, max_depth, min_size, max_weight: objective_function(p, max_depth, min_size, max_weight, start, fin, splt), pbounds=pbounds, random_state=1)\n",
    "    acq_function = UtilityFunction(kind=\"ei\", kappa=5, kappa_decay=0.8)\n",
    "    optimizer.maximize(init_points, n_iter, acquisition_function = acq_function)\n",
    "    opt_params  = optimizer.max['params']\n",
    "    return opt_params\n",
    "def ARXT_tree(splt, tune):\n",
    "    start_time = time.time()\n",
    "    train_len = 1000\n",
    "    # Define hyperparameter bounds\n",
    "    pbounds = {\n",
    "        \"p\": (5, 20),\n",
    "        \"max_depth\":(10, 150),\n",
    "        \"min_size\":(1, 50),\n",
    "        \"max_weight\": (0.01, 0.15)\n",
    "    }\n",
    "    opt_params = optimizer(pbounds, 0 , train_len, splt)\n",
    "    p, max_depth, min_size, max_weight = round(opt_params['p']), round(opt_params['max_depth']), round(opt_params['min_size']), opt_params['max_weight']\n",
    "    next_pbounds = {\"p\": (p*0.7, p*1.3), \"max_depth\" : (max_depth*0.7, max_depth*1.3), \"min_size\" : (min_size*0.7, min_size*1.3), \"max_weight\" : (max(0.001, max_weight*0.7), max_weight*1.3)}\n",
    "\n",
    "    ART = ARXT.AutoregressiveTree(p, splt=splt)    \n",
    "\n",
    "    _, _, tree, _, _ = train_run_tree(data=DATA.iloc[200:train_len], p=p, max_depth=max_depth, min_size=min_size, max_weight=max_weight, splt=splt)\n",
    "    c_det = bayes_models.OnlineChagepoint(np.array(DATA[0]), constant_hazard, 200)\n",
    "    log_likelihood_class = c_det.warm_run(llc = online_ll.StudentT(alpha=0.1, beta=.01, kappa=1, mu=0),t = train_len)\n",
    "    Nw = 200\n",
    "    forecasts = []\n",
    "    retraining_points = []\n",
    "    for i in range(train_len, len(DATA[0])):\n",
    "        forecasts.append(ARXT.forecast(DATA.iloc[i-200:i], tree, ART, p))\n",
    "\n",
    "        if c_det.iteration(i, log_likelihood_class, Nw):\n",
    "            print(\"retraining at \", DATA.index[i])\n",
    "            retraining_points.append(DATA.index[i])\n",
    "            if tune:\n",
    "                opt_params = optimizer(next_pbounds, i-500, i, splt, init_points=5, n_iter = 10)\n",
    "                p, max_depth, min_size, max_weight = round(opt_params['p']), round(opt_params['max_depth']), round(opt_params['min_size']), opt_params['max_weight']\n",
    "                next_pbounds = {\"p\": (p*0.7, p*1.3), \"max_depth\" : (max_depth*0.7, max_depth*1.3), \"min_size\" : (min_size*0.7, min_size*1.3), \"max_weight\" : (max(0.001, max_weight*0.7), max_weight*1.3)}\n",
    "\n",
    "            ART = ARXT.AutoregressiveTree(p, splt=splt)    \n",
    "    \n",
    "            _, _, tree, _, _ = train_run_tree(data=DATA[i-600:i], p=p, max_depth=max_depth, min_size=min_size, max_weight=max_weight, splt=splt)\n",
    "    retrain = \"retrain\"\n",
    "    if tune: retrain = \"retune\"\n",
    "    pd.DataFrame(forecasts).to_csv(\"forecasts_{}_{}.csv\".format(splt, retrain))\n",
    "    pd.DataFrame(retraining_points).to_csv(\"retraining_points.csv\".format(splt))\n",
    "\n",
    "    plt.plot(DATA.iloc[train_len:,0], label=\"truth\")\n",
    "    plt.plot(forecasts, label=\"forecasts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    end_time = time.time()\n",
    "    duration = end_time-start_time\n",
    "    print(\"Time taken for ARXT {} {}: {}\".format(splt, retrain, duration))\n",
    "    return forecasts, retraining_points\n",
    "\n",
    "# ARTX_exog_tuned, retraining_points = ARXT_tree(\"exog\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AR_p:\n",
    "    def __init__(self,  data, p):\n",
    "        self.data = data\n",
    "        self.p = p\n",
    "        self.lagged_data = self.gen_lagged_data(data)\n",
    "        self.m = 0 \n",
    "        self.coeffs = []\n",
    "        # self.X = []\n",
    "\n",
    "    def gen_lagged_data(self, data):\n",
    "        d = []\n",
    "        temp_data = data[0]\n",
    "        temp = []\n",
    "        for i in range(self.p, len(temp_data)):\n",
    "            temp.append(temp_data[i - self.p:i].iloc[::-1])\n",
    "\n",
    "        d.append(temp)\n",
    "        data = np.concatenate(d, axis = 1)\n",
    "        return(data)\n",
    "\n",
    "        \n",
    "    def AR_p_model(self, start, train_len):\n",
    "\n",
    "        data = self.lagged_data[start:train_len]\n",
    "        # Add intercept term (column of ones) to X\n",
    "        X = np.hstack([np.ones((data.shape[0], 1)), data[:,1:]])\n",
    "        self.X = X\n",
    "        y = data[:,0]\n",
    "        self.y = y\n",
    "        # print(X)\n",
    "        # Estimate coefficients using OLS\n",
    "        coeffs, residuals, rank, s = lstsq(X, y, rcond=None)\n",
    "        self.coeffs = coeffs[1:]\n",
    "        if residuals.size == 0:\n",
    "            residuals = np.sum((y - X.dot(coeffs))**2)\n",
    "        self.m = [coeffs[0]]\n",
    "    \n",
    "    def predict(self, data):\n",
    "\n",
    "        # d = []\n",
    "        # full = data[0]\n",
    "        # for_val = data[::-1]\n",
    "        # print(for_val, data)\n",
    "        # for_val = np.concatenate(d)\n",
    "        d = np.array(data)\n",
    "        prediction = np.dot(d[1:][:,np.newaxis].T,self.coeffs) + self.m  \n",
    "        # prediction = np.dot(data.iloc[1:][:,np.newaxis].T,self.coeffs) + self.m  \n",
    "\n",
    "        return(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARX_p:\n",
    "    def __init__(self,  data, p):\n",
    "        self.data = data\n",
    "        self.p = p\n",
    "        self.lagged_data = self.gen_lagged_data(data)\n",
    "        self.m = 0 \n",
    "        self.coeffs = []\n",
    "\n",
    "    def gen_lagged_data(self, data):\n",
    "        d = []\n",
    "        for ind in range(data.shape[1]):\n",
    "            temp_data = data[ind]\n",
    "            temp = []\n",
    "            for i in range(self.p, len(temp_data)):\n",
    "                temp.append(temp_data[i- self.p:i].iloc[::-1])\n",
    "            d.append(temp)\n",
    "        data = np.concatenate(d, axis = 1)\n",
    "        return(data)\n",
    "\n",
    "        \n",
    "    def ARX_p_model(self, start, train_len):\n",
    "\n",
    "        data = self.lagged_data[start:train_len]\n",
    "        # Add intercept term (column of ones) to X\n",
    "        X = np.hstack([np.ones((data.shape[0], 1)), data[:, 1:]])\n",
    "        y = data[:,0]\n",
    "        self.X, self.y = X, y\n",
    "        # Estimate coefficients using OLS\n",
    "        coeffs, residuals, rank, s = lstsq(X, y, rcond=None)\n",
    "        self.coeffs = coeffs[1:]\n",
    "        if residuals.size == 0:\n",
    "            residuals = np.sum((y - X.dot(coeffs))**2)\n",
    "        self.m = [coeffs[0]]\n",
    "    \n",
    "    def predict(self, data):\n",
    "\n",
    "        d = []\n",
    "        for ind in range(data.shape[1]):\n",
    "            full = data[ind]\n",
    "            d.append(full[-self.p:].iloc[::-1])\n",
    "        for_val = np.concatenate(d)\n",
    "        prediction = np.dot(for_val[1:][:,np.newaxis].T,self.coeffs) + self.m  \n",
    "\n",
    "        return(prediction[0])\n"
=======
    "    print(differencing)\n",
    "    if differencing:\n",
    "        data = data.pct_change()\n",
    "        data = data.iloc[1:]\n",
    "    return(data)\n"
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 121,
=======
   "execution_count": 36,
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Time taken for AR(p) : 0.18341760635375975 mins\n"
=======
      "retraining at  2007-08-09\n",
      "retraining at  2021-01-12\n",
      "Time taken for AR(p) retune: 9.786260843276978\n"
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# def AR_model(p, train):\n",
    "p = 5\n",
    "train = False\n",
    "start_time = time.time()\n",
    "train_len = 1000\n",
    "AR = ARX_p(DATA, p)    \n",
    "\n",
    "AR.ARX_p_model(0, train_len)\n",
=======
    "DATA = get_data(differencing=True)\n",
    "p = 5\n",
    "train = True\n",
    "\n",
    "start_time = time.time()\n",
    "train_len = 1000\n",
    "AR = ARXT.AR_p(DATA, p)    \n",
    "\n",
    "AR.AR_p_model(0, train_len)\n",
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
    "c_det = bayes_models.OnlineChagepoint(np.array(DATA[0]), constant_hazard, 200)\n",
    "log_likelihood_class = c_det.warm_run(llc = online_ll.StudentT(alpha=0.1, beta=.01, kappa=1, mu=0),t = train_len)\n",
    "Nw = 200\n",
    "forecasts = []\n",
    "retraining_points = []\n",
<<<<<<< HEAD
    "for i in range(train_len, len(DATA[0])- p):\n",
=======
    "for i in range(train_len, len(DATA[0])):\n",
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
    "    if train:\n",
    "        if c_det.iteration(i, log_likelihood_class, Nw):\n",
    "            print(\"retraining at \", DATA.index[i])\n",
    "            retraining_points.append(DATA.index[i])\n",
<<<<<<< HEAD
    "            AR.ARX_p_model(max(0,i-500), i)\n",
    "\n",
    "    forecasts.append(AR.predict(DATA.iloc[i-p:i, :]))\n",
    "\n",
=======
    "            AR.AR_p_model(max(0,i-500), i)\n",
    "\n",
    "    forecasts.append(AR.predict(DATA[i-p:i]))\n",
    "\n",
    "# plt.plot(DATA.iloc[train_len:,0], label=\"truth\")\n",
    "# plt.plot(forecasts, label=\"forecasts\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
    "retrain = \"\"\n",
    "if train: retrain = \"retune\"\n",
    "end_time = time.time()\n",
    "duration = end_time-start_time\n",
<<<<<<< HEAD
    "print(\"Time taken for AR(p) {}: {} mins\".format(retrain, duration/60))\n",
    "\n",
    "\n",
    "# AR_model(5, True)"
=======
    "print(\"Time taken for AR(p) {}: {}\".format(retrain, duration))\n",
    "pd.DataFrame(forecasts).to_csv(\"forecasts_AR_{}.csv\".format(retrain))"
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 152,
=======
   "execution_count": 104,
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Time taken for AR(p) : 21.955553150177003 mins\n"
     ]
    }
   ],
   "source": [
    "# def AR_model(p, train):\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "p = 5\n",
    "start_time = time.time()\n",
    "train_len = 1000\n",
    "forecasts = []\n",
    "retraining_points = []\n",
    "for i in range(train_len, len(DATA[0])- p):\n",
    "    moving_val = DATA.iloc[i-p*5:i,0]\n",
    "    model = ARIMA(moving_val, order=(p,1,0))\n",
    "    model_fit = model.fit()\n",
    "    forecasts.append(model_fit.forecast()[0])\n",
    "end_time = time.time()\n",
    "duration = end_time-start_time\n",
    "print(\"Time taken for AR({}): {} mins\".format(p, duration/60))\n",
    "\n",
    "\n",
    "# AR_model(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006-11-02    1.155016\n",
       "Freq: B, dtype: float64"
      ]
     },
     "execution_count": 147,
=======
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-02</th>\n",
       "      <td>0.033200</td>\n",
       "      <td>-0.012478</td>\n",
       "      <td>0.031875</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>-0.112858</td>\n",
       "      <td>0.028072</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>-0.005716</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>-0.000484</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>-0.000677</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>-0.027964</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>-0.043233</td>\n",
       "      <td>-0.005749</td>\n",
       "      <td>-0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>0.022474</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>0.024685</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>0.085370</td>\n",
       "      <td>0.031986</td>\n",
       "      <td>-0.016625</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>-0.006545</td>\n",
       "      <td>-0.007154</td>\n",
       "      <td>-0.003759</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>-0.013479</td>\n",
       "      <td>0.022877</td>\n",
       "      <td>-0.005513</td>\n",
       "      <td>-0.006135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>-0.014086</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>-0.016621</td>\n",
       "      <td>-0.021305</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>-0.024559</td>\n",
       "      <td>-0.031323</td>\n",
       "      <td>-0.005543</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>-0.008725</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>-0.004050</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>-0.013777</td>\n",
       "      <td>0.037374</td>\n",
       "      <td>-0.000268</td>\n",
       "      <td>-0.004697</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>0.027273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>-0.012021</td>\n",
       "      <td>-0.005409</td>\n",
       "      <td>-0.011006</td>\n",
       "      <td>-0.013517</td>\n",
       "      <td>0.022633</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.004762</td>\n",
       "      <td>0.008850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>0.017461</td>\n",
       "      <td>-0.004089</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>-0.031617</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>-0.004785</td>\n",
       "      <td>-0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-0.002541</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>-0.002214</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>-0.004808</td>\n",
       "      <td>0.013216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5217 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5  \\\n",
       "Date                                                                     \n",
       "2003-01-02  0.033200 -0.012478  0.031875  0.036945 -0.112858  0.028072   \n",
       "2003-01-03 -0.000484  0.004512 -0.000677  0.001610 -0.027964  0.003065   \n",
       "2003-01-06  0.022474  0.002597  0.019982  0.024685  0.009319  0.085370   \n",
       "2003-01-07 -0.006545 -0.007154 -0.003759  0.007212  0.008832 -0.013479   \n",
       "2003-01-08 -0.014086  0.009319 -0.016621 -0.021305  0.015917 -0.024559   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-12-26  0.000000 -0.003261  0.000000  0.000000  0.000000 -0.002700   \n",
       "2022-12-27 -0.004050  0.000196  0.001133 -0.013777  0.037374 -0.000268   \n",
       "2022-12-28 -0.012021 -0.005409 -0.011006 -0.013517  0.022633 -0.000714   \n",
       "2022-12-29  0.017461 -0.004089  0.010497  0.025927 -0.031617  0.002940   \n",
       "2022-12-30 -0.002541  0.008411 -0.002214 -0.001108  0.010728  0.006097   \n",
       "\n",
       "                   6         7         8  \n",
       "Date                                      \n",
       "2003-01-02  0.023364 -0.005716  0.000000  \n",
       "2003-01-03 -0.043233 -0.005749 -0.012195  \n",
       "2003-01-06  0.031986 -0.016625  0.006173  \n",
       "2003-01-07  0.022877 -0.005513 -0.006135  \n",
       "2003-01-08 -0.031323 -0.005543  0.055556  \n",
       "...              ...       ...       ...  \n",
       "2022-12-26  0.002481 -0.008725  0.000000  \n",
       "2022-12-27 -0.004697 -0.004739  0.027273  \n",
       "2022-12-28  0.000295 -0.004762  0.008850  \n",
       "2022-12-29  0.002020 -0.004785 -0.004386  \n",
       "2022-12-30  0.004065 -0.004808  0.013216  \n",
       "\n",
       "[5217 rows x 9 columns]"
      ]
     },
     "execution_count": 104,
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "model_fit.forecast()\n",
    "# DATA.iloc[i,0]"
=======
    "DATA = get_data(differencing=True)\n",
    "DATA"
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
=======
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
<<<<<<< HEAD
=======
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>6_3</th>\n",
       "      <th>6_4</th>\n",
       "      <th>7_1</th>\n",
       "      <th>7_2</th>\n",
       "      <th>7_3</th>\n",
       "      <th>7_4</th>\n",
       "      <th>8_1</th>\n",
       "      <th>8_2</th>\n",
       "      <th>8_3</th>\n",
       "      <th>8_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.080017</td>\n",
       "      <td>20.419983</td>\n",
       "      <td>-0.440002</td>\n",
       "      <td>29.210022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-6.080017</td>\n",
       "      <td>20.419983</td>\n",
       "      <td>-0.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.640015</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-6.080017</td>\n",
       "      <td>20.419983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.640015</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-6.080017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.309998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.640015</td>\n",
       "      <td>-13.000000</td>\n",
=======
       "      <th>2003-01-09</th>\n",
       "      <td>0.019386</td>\n",
       "      <td>-0.002262</td>\n",
       "      <td>0.021043</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>-0.050137</td>\n",
       "      <td>-0.028723</td>\n",
       "      <td>-0.025819</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031986</td>\n",
       "      <td>-0.043233</td>\n",
       "      <td>-0.005543</td>\n",
       "      <td>-0.005513</td>\n",
       "      <td>-0.016625</td>\n",
       "      <td>-0.005749</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-0.006135</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>-0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.068821</td>\n",
       "      <td>0.062054</td>\n",
       "      <td>-0.005605</td>\n",
       "      <td>-0.016854</td>\n",
       "      <td>-0.002262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022877</td>\n",
       "      <td>0.031986</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>-0.005543</td>\n",
       "      <td>-0.005513</td>\n",
       "      <td>-0.016625</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-0.006135</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-13</th>\n",
       "      <td>-0.001412</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.001160</td>\n",
       "      <td>0.023849</td>\n",
       "      <td>-0.100171</td>\n",
       "      <td>-0.040372</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031323</td>\n",
       "      <td>0.022877</td>\n",
       "      <td>-0.005605</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>-0.005543</td>\n",
       "      <td>-0.005513</td>\n",
       "      <td>-0.016854</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-0.006135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-14</th>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>-0.013253</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>-0.005650</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025819</td>\n",
       "      <td>-0.031323</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>-0.005605</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>-0.005543</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>-0.016854</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-15</th>\n",
       "      <td>-0.014426</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>-0.015188</td>\n",
       "      <td>0.038258</td>\n",
       "      <td>-0.001325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062054</td>\n",
       "      <td>-0.025819</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>-0.005605</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>-0.005650</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>-0.016854</td>\n",
       "      <td>0.040936</td>\n",
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
<<<<<<< HEAD
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.590088</td>\n",
       "      <td>-11.739990</td>\n",
       "      <td>6.859985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.129883</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.590088</td>\n",
       "      <td>-11.739990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.470093</td>\n",
       "      <td>-10.129883</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.590088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.039917</td>\n",
       "      <td>-0.470093</td>\n",
       "      <td>-10.129883</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.479980</td>\n",
       "      <td>-3.039917</td>\n",
       "      <td>-0.470093</td>\n",
       "      <td>-10.129883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1          2          3          4\n",
       "0    1.0  -6.080017  20.419983  -0.440002  29.210022\n",
       "1    1.0 -13.000000  -6.080017  20.419983  -0.440002\n",
       "2    1.0  17.640015 -13.000000  -6.080017  20.419983\n",
       "3    1.0   0.000000  17.640015 -13.000000  -6.080017\n",
       "4    1.0  -1.309998   0.000000  17.640015 -13.000000\n",
       "..   ...        ...        ...        ...        ...\n",
       "995  1.0   0.009888   0.590088 -11.739990   6.859985\n",
       "996  1.0 -10.129883   0.009888   0.590088 -11.739990\n",
       "997  1.0  -0.470093 -10.129883   0.009888   0.590088\n",
       "998  1.0  -3.039917  -0.470093 -10.129883   0.009888\n",
       "999  1.0  15.479980  -3.039917  -0.470093 -10.129883\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
=======
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>-0.008725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009238</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>-0.035242</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.041860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>-0.004050</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>-0.013777</td>\n",
       "      <td>0.037374</td>\n",
       "      <td>-0.000268</td>\n",
       "      <td>-0.004697</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003014</td>\n",
       "      <td>-0.009238</td>\n",
       "      <td>-0.008725</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>-0.035242</td>\n",
       "      <td>0.013393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>-0.012021</td>\n",
       "      <td>-0.005409</td>\n",
       "      <td>-0.011006</td>\n",
       "      <td>-0.013517</td>\n",
       "      <td>0.022633</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.004762</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-0.003014</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>-0.008725</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>-0.035242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>0.017461</td>\n",
       "      <td>-0.004089</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>-0.031617</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>-0.004785</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>-0.005409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-0.004762</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>-0.008725</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-0.002541</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>-0.002214</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>-0.004808</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.004089</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004697</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>-0.004785</td>\n",
       "      <td>-0.004762</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>-0.008725</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5212 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5  \\\n",
       "Date                                                                     \n",
       "2003-01-09  0.019386 -0.002262  0.021043  0.026687 -0.050137 -0.028723   \n",
       "2003-01-10  0.000000  0.000671  0.000992  0.006437  0.002887  0.068821   \n",
       "2003-01-13 -0.001412  0.000503  0.000124 -0.001160  0.023849 -0.100171   \n",
       "2003-01-14  0.005830  0.010508  0.006447  0.010339 -0.013253  0.002657   \n",
       "2003-01-15 -0.014426 -0.000931 -0.013507 -0.015188  0.038258 -0.001325   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-12-26  0.000000 -0.003261  0.000000  0.000000  0.000000 -0.002700   \n",
       "2022-12-27 -0.004050  0.000196  0.001133 -0.013777  0.037374 -0.000268   \n",
       "2022-12-28 -0.012021 -0.005409 -0.011006 -0.013517  0.022633 -0.000714   \n",
       "2022-12-29  0.017461 -0.004089  0.010497  0.025927 -0.031617  0.002940   \n",
       "2022-12-30 -0.002541  0.008411 -0.002214 -0.001108  0.010728  0.006097   \n",
       "\n",
       "                   6         7         8       1_1  ...       6_3       6_4  \\\n",
       "Date                                                ...                       \n",
       "2003-01-09 -0.025819 -0.005574  0.040936  0.009319  ...  0.031986 -0.043233   \n",
       "2003-01-10  0.062054 -0.005605 -0.016854 -0.002262  ...  0.022877  0.031986   \n",
       "2003-01-13 -0.040372  0.012401  0.011429  0.000671  ... -0.031323  0.022877   \n",
       "2003-01-14  0.002876  0.008909 -0.005650  0.000503  ... -0.025819 -0.031323   \n",
       "2003-01-15  0.000000  0.008830  0.022727  0.010508  ...  0.062054 -0.025819   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2022-12-26  0.002481 -0.008725  0.000000  0.000098  ... -0.009238  0.002991   \n",
       "2022-12-27 -0.004697 -0.004739  0.027273 -0.003261  ... -0.003014 -0.009238   \n",
       "2022-12-28  0.000295 -0.004762  0.008850  0.000196  ...  0.001080 -0.003014   \n",
       "2022-12-29  0.002020 -0.004785 -0.004386 -0.005409  ...  0.002481  0.001080   \n",
       "2022-12-30  0.004065 -0.004808  0.013216 -0.004089  ... -0.004697  0.002481   \n",
       "\n",
       "                 7_1       7_2       7_3       7_4       8_1       8_2  \\\n",
       "Date                                                                     \n",
       "2003-01-09 -0.005543 -0.005513 -0.016625 -0.005749  0.055556 -0.006135   \n",
       "2003-01-10 -0.005574 -0.005543 -0.005513 -0.016625  0.040936  0.055556   \n",
       "2003-01-13 -0.005605 -0.005574 -0.005543 -0.005513 -0.016854  0.040936   \n",
       "2003-01-14  0.012401 -0.005605 -0.005574 -0.005543  0.011429 -0.016854   \n",
       "2003-01-15  0.008909  0.012401 -0.005605 -0.005574 -0.005650  0.011429   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-12-26  0.000672  0.000672  0.000672  0.000673  0.004566 -0.035242   \n",
       "2022-12-27 -0.008725  0.000672  0.000672  0.000672  0.000000  0.004566   \n",
       "2022-12-28 -0.004739 -0.008725  0.000672  0.000672  0.027273  0.000000   \n",
       "2022-12-29 -0.004762 -0.004739 -0.008725  0.000672  0.008850  0.027273   \n",
       "2022-12-30 -0.004785 -0.004762 -0.004739 -0.008725 -0.004386  0.008850   \n",
       "\n",
       "                 8_3       8_4  \n",
       "Date                            \n",
       "2003-01-09  0.006173 -0.012195  \n",
       "2003-01-10 -0.006135  0.006173  \n",
       "2003-01-13  0.055556 -0.006135  \n",
       "2003-01-14  0.040936  0.055556  \n",
       "2003-01-15 -0.016854  0.040936  \n",
       "...              ...       ...  \n",
       "2022-12-26  0.013393  0.041860  \n",
       "2022-12-27 -0.035242  0.013393  \n",
       "2022-12-28  0.004566 -0.035242  \n",
       "2022-12-29  0.000000  0.004566  \n",
       "2022-12-30  0.027273  0.000000  \n",
       "\n",
       "[5212 rows x 41 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data(differencing=True)\n",
    "for i in df.columns[1:]:\n",
    "    for lag in range(1,p):\n",
    "\n",
    "        df[f'{i}_{lag}'] = df[i].shift(lag)\n",
    "\n",
    "# df = df.dropna(inplace=True, axis=1)\n",
    "\n",
    "df = df.iloc[p:,:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "model = ARIMA(endog=df.iloc[:1000,0], exog=df.iloc[:1000,1:], order=(p,1,0))\n",
    "model_fit = model.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_temp = []\n",
    "for i in range(1000):\n",
    "    prediction_temp.append(model_fit.forecast(exog=df.iloc[i-1,1:])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48348348348348347\n",
      "0.5015015015015015\n"
     ]
    }
   ],
   "source": [
    "print(hit_rate(df.iloc[1000:2000,0], prediction_temp))\n",
    "print(hit_rate(df.iloc[1000:2000,0], forecasts[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019109453048249254\n",
      "0.02346021434730719\n"
     ]
    }
   ],
   "source": [
    "print(sqrt(mean_squared_error(df.iloc[1000:2000,0], prediction_temp)))\n",
    "print(sqrt(mean_squared_error(df.iloc[1000:2000,0], forecasts[:1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>SARIMAX Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>    <td>1000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>ARIMA(5, 1, 0)</td>  <th>  Log Likelihood     </th>  <td>5124.972</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 01 Dec 2023</td> <th>  AIC                </th> <td>-10157.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:40:21</td>     <th>  BIC                </th>  <td>-9932.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>             <td>01-09-2003</td>    <th>  HQIC               </th> <td>-10072.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                   <td>- 11-08-2006</td>   <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>opg</td>       <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>      <td>    0.0087</td> <td>    0.008</td> <td>    1.091</td> <td> 0.275</td> <td>   -0.007</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>      <td>    0.6889</td> <td>    0.011</td> <td>   62.494</td> <td> 0.000</td> <td>    0.667</td> <td>    0.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>      <td>    0.2319</td> <td>    0.008</td> <td>   28.267</td> <td> 0.000</td> <td>    0.216</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>      <td>   -0.0051</td> <td>    0.001</td> <td>   -3.872</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>      <td>   -0.0038</td> <td>    0.004</td> <td>   -1.047</td> <td> 0.295</td> <td>   -0.011</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>      <td>    0.0073</td> <td>    0.004</td> <td>    1.810</td> <td> 0.070</td> <td>   -0.001</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>      <td>    0.0017</td> <td>    0.008</td> <td>    0.211</td> <td> 0.833</td> <td>   -0.014</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>      <td>    0.0034</td> <td>    0.004</td> <td>    0.878</td> <td> 0.380</td> <td>   -0.004</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1_1</th>    <td>    0.0076</td> <td>    0.008</td> <td>    0.910</td> <td> 0.363</td> <td>   -0.009</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1_2</th>    <td>   -0.0343</td> <td>    0.009</td> <td>   -3.876</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1_3</th>    <td>    0.0102</td> <td>    0.009</td> <td>    1.139</td> <td> 0.255</td> <td>   -0.007</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1_4</th>    <td>    0.0045</td> <td>    0.009</td> <td>    0.519</td> <td> 0.604</td> <td>   -0.013</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2_1</th>    <td>   -0.0436</td> <td>    0.012</td> <td>   -3.572</td> <td> 0.000</td> <td>   -0.067</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2_2</th>    <td>   -0.0011</td> <td>    0.011</td> <td>   -0.093</td> <td> 0.926</td> <td>   -0.024</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2_3</th>    <td>   -0.0070</td> <td>    0.012</td> <td>   -0.592</td> <td> 0.554</td> <td>   -0.030</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2_4</th>    <td>   -0.0118</td> <td>    0.011</td> <td>   -1.036</td> <td> 0.300</td> <td>   -0.034</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3_1</th>    <td>    0.0060</td> <td>    0.008</td> <td>    0.741</td> <td> 0.459</td> <td>   -0.010</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3_2</th>    <td>    0.0016</td> <td>    0.008</td> <td>    0.200</td> <td> 0.841</td> <td>   -0.014</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3_3</th>    <td>   -0.0057</td> <td>    0.008</td> <td>   -0.684</td> <td> 0.494</td> <td>   -0.022</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3_4</th>    <td>    0.0038</td> <td>    0.008</td> <td>    0.481</td> <td> 0.631</td> <td>   -0.012</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4_1</th>    <td>   -0.0026</td> <td>    0.001</td> <td>   -2.237</td> <td> 0.025</td> <td>   -0.005</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4_2</th>    <td>    0.0005</td> <td>    0.001</td> <td>    0.423</td> <td> 0.672</td> <td>   -0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4_3</th>    <td>   -0.0027</td> <td>    0.001</td> <td>   -2.236</td> <td> 0.025</td> <td>   -0.005</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4_4</th>    <td>   -0.0023</td> <td>    0.001</td> <td>   -1.661</td> <td> 0.097</td> <td>   -0.005</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5_1</th>    <td>    0.0002</td> <td>    0.004</td> <td>    0.060</td> <td> 0.953</td> <td>   -0.007</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5_2</th>    <td>    0.0004</td> <td>    0.003</td> <td>    0.123</td> <td> 0.902</td> <td>   -0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5_3</th>    <td>   -0.0055</td> <td>    0.004</td> <td>   -1.555</td> <td> 0.120</td> <td>   -0.012</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5_4</th>    <td>    0.0010</td> <td>    0.003</td> <td>    0.291</td> <td> 0.771</td> <td>   -0.006</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6_1</th>    <td>   -0.0014</td> <td>    0.004</td> <td>   -0.342</td> <td> 0.732</td> <td>   -0.009</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6_2</th>    <td>   -0.0007</td> <td>    0.004</td> <td>   -0.172</td> <td> 0.864</td> <td>   -0.008</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6_3</th>    <td>    0.0065</td> <td>    0.004</td> <td>    1.556</td> <td> 0.120</td> <td>   -0.002</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6_4</th>    <td>   -0.0040</td> <td>    0.004</td> <td>   -1.004</td> <td> 0.315</td> <td>   -0.012</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7_1</th>    <td>    0.0047</td> <td>    0.008</td> <td>    0.574</td> <td> 0.566</td> <td>   -0.011</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7_2</th>    <td>   -0.0054</td> <td>    0.009</td> <td>   -0.611</td> <td> 0.541</td> <td>   -0.023</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7_3</th>    <td>    0.0038</td> <td>    0.008</td> <td>    0.486</td> <td> 0.627</td> <td>   -0.012</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7_4</th>    <td>   -0.0013</td> <td>    0.007</td> <td>   -0.176</td> <td> 0.860</td> <td>   -0.015</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8_1</th>    <td>   -0.0065</td> <td>    0.003</td> <td>   -1.865</td> <td> 0.062</td> <td>   -0.013</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8_2</th>    <td>   -0.0046</td> <td>    0.004</td> <td>   -1.102</td> <td> 0.270</td> <td>   -0.013</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8_3</th>    <td>    0.0082</td> <td>    0.003</td> <td>    2.430</td> <td> 0.015</td> <td>    0.002</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8_4</th>    <td>   -0.0027</td> <td>    0.004</td> <td>   -0.680</td> <td> 0.496</td> <td>   -0.010</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L1</th>  <td>   -0.7692</td> <td>    0.032</td> <td>  -24.011</td> <td> 0.000</td> <td>   -0.832</td> <td>   -0.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L2</th>  <td>   -0.6443</td> <td>    0.042</td> <td>  -15.450</td> <td> 0.000</td> <td>   -0.726</td> <td>   -0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L3</th>  <td>   -0.4673</td> <td>    0.044</td> <td>  -10.534</td> <td> 0.000</td> <td>   -0.554</td> <td>   -0.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L4</th>  <td>   -0.3058</td> <td>    0.042</td> <td>   -7.206</td> <td> 0.000</td> <td>   -0.389</td> <td>   -0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L5</th>  <td>   -0.1566</td> <td>    0.034</td> <td>   -4.630</td> <td> 0.000</td> <td>   -0.223</td> <td>   -0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigma2</th> <td> 2.029e-06</td> <td> 8.72e-08</td> <td>   23.267</td> <td> 0.000</td> <td> 1.86e-06</td> <td>  2.2e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Ljung-Box (L1) (Q):</th>     <td>1.09</td> <th>  Jarque-Bera (JB):  </th> <td>21.91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Q):</th>                <td>0.30</td> <th>  Prob(JB):          </th> <td>0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Heteroskedasticity (H):</th> <td>0.92</td> <th>  Skew:              </th> <td>0.12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(H) (two-sided):</th>    <td>0.48</td> <th>  Kurtosis:          </th> <td>3.69</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}          &        y         & \\textbf{  No. Observations:  } &    1000     \\\\\n",
       "\\textbf{Model:}                  &  ARIMA(5, 1, 0)  & \\textbf{  Log Likelihood     } &  5124.972   \\\\\n",
       "\\textbf{Date:}                   & Fri, 01 Dec 2023 & \\textbf{  AIC                } & -10157.944  \\\\\n",
       "\\textbf{Time:}                   &     09:40:21     & \\textbf{  BIC                } & -9932.234   \\\\\n",
       "\\textbf{Sample:}                 &    01-09-2003    & \\textbf{  HQIC               } & -10072.154  \\\\\n",
       "\\textbf{}                        &   - 11-08-2006   & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}        &       opg        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{1}      &       0.0087  &        0.008     &     1.091  &         0.275        &       -0.007    &        0.024     \\\\\n",
       "\\textbf{2}      &       0.6889  &        0.011     &    62.494  &         0.000        &        0.667    &        0.711     \\\\\n",
       "\\textbf{3}      &       0.2319  &        0.008     &    28.267  &         0.000        &        0.216    &        0.248     \\\\\n",
       "\\textbf{4}      &      -0.0051  &        0.001     &    -3.872  &         0.000        &       -0.008    &       -0.003     \\\\\n",
       "\\textbf{5}      &      -0.0038  &        0.004     &    -1.047  &         0.295        &       -0.011    &        0.003     \\\\\n",
       "\\textbf{6}      &       0.0073  &        0.004     &     1.810  &         0.070        &       -0.001    &        0.015     \\\\\n",
       "\\textbf{7}      &       0.0017  &        0.008     &     0.211  &         0.833        &       -0.014    &        0.018     \\\\\n",
       "\\textbf{8}      &       0.0034  &        0.004     &     0.878  &         0.380        &       -0.004    &        0.011     \\\\\n",
       "\\textbf{1\\_1}   &       0.0076  &        0.008     &     0.910  &         0.363        &       -0.009    &        0.024     \\\\\n",
       "\\textbf{1\\_2}   &      -0.0343  &        0.009     &    -3.876  &         0.000        &       -0.052    &       -0.017     \\\\\n",
       "\\textbf{1\\_3}   &       0.0102  &        0.009     &     1.139  &         0.255        &       -0.007    &        0.028     \\\\\n",
       "\\textbf{1\\_4}   &       0.0045  &        0.009     &     0.519  &         0.604        &       -0.013    &        0.022     \\\\\n",
       "\\textbf{2\\_1}   &      -0.0436  &        0.012     &    -3.572  &         0.000        &       -0.067    &       -0.020     \\\\\n",
       "\\textbf{2\\_2}   &      -0.0011  &        0.011     &    -0.093  &         0.926        &       -0.024    &        0.021     \\\\\n",
       "\\textbf{2\\_3}   &      -0.0070  &        0.012     &    -0.592  &         0.554        &       -0.030    &        0.016     \\\\\n",
       "\\textbf{2\\_4}   &      -0.0118  &        0.011     &    -1.036  &         0.300        &       -0.034    &        0.011     \\\\\n",
       "\\textbf{3\\_1}   &       0.0060  &        0.008     &     0.741  &         0.459        &       -0.010    &        0.022     \\\\\n",
       "\\textbf{3\\_2}   &       0.0016  &        0.008     &     0.200  &         0.841        &       -0.014    &        0.018     \\\\\n",
       "\\textbf{3\\_3}   &      -0.0057  &        0.008     &    -0.684  &         0.494        &       -0.022    &        0.011     \\\\\n",
       "\\textbf{3\\_4}   &       0.0038  &        0.008     &     0.481  &         0.631        &       -0.012    &        0.020     \\\\\n",
       "\\textbf{4\\_1}   &      -0.0026  &        0.001     &    -2.237  &         0.025        &       -0.005    &       -0.000     \\\\\n",
       "\\textbf{4\\_2}   &       0.0005  &        0.001     &     0.423  &         0.672        &       -0.002    &        0.003     \\\\\n",
       "\\textbf{4\\_3}   &      -0.0027  &        0.001     &    -2.236  &         0.025        &       -0.005    &       -0.000     \\\\\n",
       "\\textbf{4\\_4}   &      -0.0023  &        0.001     &    -1.661  &         0.097        &       -0.005    &        0.000     \\\\\n",
       "\\textbf{5\\_1}   &       0.0002  &        0.004     &     0.060  &         0.953        &       -0.007    &        0.007     \\\\\n",
       "\\textbf{5\\_2}   &       0.0004  &        0.003     &     0.123  &         0.902        &       -0.006    &        0.007     \\\\\n",
       "\\textbf{5\\_3}   &      -0.0055  &        0.004     &    -1.555  &         0.120        &       -0.012    &        0.001     \\\\\n",
       "\\textbf{5\\_4}   &       0.0010  &        0.003     &     0.291  &         0.771        &       -0.006    &        0.008     \\\\\n",
       "\\textbf{6\\_1}   &      -0.0014  &        0.004     &    -0.342  &         0.732        &       -0.009    &        0.007     \\\\\n",
       "\\textbf{6\\_2}   &      -0.0007  &        0.004     &    -0.172  &         0.864        &       -0.008    &        0.007     \\\\\n",
       "\\textbf{6\\_3}   &       0.0065  &        0.004     &     1.556  &         0.120        &       -0.002    &        0.015     \\\\\n",
       "\\textbf{6\\_4}   &      -0.0040  &        0.004     &    -1.004  &         0.315        &       -0.012    &        0.004     \\\\\n",
       "\\textbf{7\\_1}   &       0.0047  &        0.008     &     0.574  &         0.566        &       -0.011    &        0.021     \\\\\n",
       "\\textbf{7\\_2}   &      -0.0054  &        0.009     &    -0.611  &         0.541        &       -0.023    &        0.012     \\\\\n",
       "\\textbf{7\\_3}   &       0.0038  &        0.008     &     0.486  &         0.627        &       -0.012    &        0.019     \\\\\n",
       "\\textbf{7\\_4}   &      -0.0013  &        0.007     &    -0.176  &         0.860        &       -0.015    &        0.013     \\\\\n",
       "\\textbf{8\\_1}   &      -0.0065  &        0.003     &    -1.865  &         0.062        &       -0.013    &        0.000     \\\\\n",
       "\\textbf{8\\_2}   &      -0.0046  &        0.004     &    -1.102  &         0.270        &       -0.013    &        0.004     \\\\\n",
       "\\textbf{8\\_3}   &       0.0082  &        0.003     &     2.430  &         0.015        &        0.002    &        0.015     \\\\\n",
       "\\textbf{8\\_4}   &      -0.0027  &        0.004     &    -0.680  &         0.496        &       -0.010    &        0.005     \\\\\n",
       "\\textbf{ar.L1}  &      -0.7692  &        0.032     &   -24.011  &         0.000        &       -0.832    &       -0.706     \\\\\n",
       "\\textbf{ar.L2}  &      -0.6443  &        0.042     &   -15.450  &         0.000        &       -0.726    &       -0.563     \\\\\n",
       "\\textbf{ar.L3}  &      -0.4673  &        0.044     &   -10.534  &         0.000        &       -0.554    &       -0.380     \\\\\n",
       "\\textbf{ar.L4}  &      -0.3058  &        0.042     &    -7.206  &         0.000        &       -0.389    &       -0.223     \\\\\n",
       "\\textbf{ar.L5}  &      -0.1566  &        0.034     &    -4.630  &         0.000        &       -0.223    &       -0.090     \\\\\n",
       "\\textbf{sigma2} &    2.029e-06  &     8.72e-08     &    23.267  &         0.000        &     1.86e-06    &      2.2e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Ljung-Box (L1) (Q):}     & 1.09 & \\textbf{  Jarque-Bera (JB):  } & 21.91  \\\\\n",
       "\\textbf{Prob(Q):}                & 0.30 & \\textbf{  Prob(JB):          } &  0.00  \\\\\n",
       "\\textbf{Heteroskedasticity (H):} & 0.92 & \\textbf{  Skew:              } &  0.12  \\\\\n",
       "\\textbf{Prob(H) (two-sided):}    & 0.48 & \\textbf{  Kurtosis:          } &  3.69  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{SARIMAX Results}\n",
       "\\end{center}\n",
       "\n",
       "Warnings: \\newline\n",
       " [1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               SARIMAX Results                                \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1000\n",
       "Model:                 ARIMA(5, 1, 0)   Log Likelihood                5124.972\n",
       "Date:                Fri, 01 Dec 2023   AIC                         -10157.944\n",
       "Time:                        09:40:21   BIC                          -9932.234\n",
       "Sample:                    01-09-2003   HQIC                        -10072.154\n",
       "                         - 11-08-2006                                         \n",
       "Covariance Type:                  opg                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "1              0.0087      0.008      1.091      0.275      -0.007       0.024\n",
       "2              0.6889      0.011     62.494      0.000       0.667       0.711\n",
       "3              0.2319      0.008     28.267      0.000       0.216       0.248\n",
       "4             -0.0051      0.001     -3.872      0.000      -0.008      -0.003\n",
       "5             -0.0038      0.004     -1.047      0.295      -0.011       0.003\n",
       "6              0.0073      0.004      1.810      0.070      -0.001       0.015\n",
       "7              0.0017      0.008      0.211      0.833      -0.014       0.018\n",
       "8              0.0034      0.004      0.878      0.380      -0.004       0.011\n",
       "1_1            0.0076      0.008      0.910      0.363      -0.009       0.024\n",
       "1_2           -0.0343      0.009     -3.876      0.000      -0.052      -0.017\n",
       "1_3            0.0102      0.009      1.139      0.255      -0.007       0.028\n",
       "1_4            0.0045      0.009      0.519      0.604      -0.013       0.022\n",
       "2_1           -0.0436      0.012     -3.572      0.000      -0.067      -0.020\n",
       "2_2           -0.0011      0.011     -0.093      0.926      -0.024       0.021\n",
       "2_3           -0.0070      0.012     -0.592      0.554      -0.030       0.016\n",
       "2_4           -0.0118      0.011     -1.036      0.300      -0.034       0.011\n",
       "3_1            0.0060      0.008      0.741      0.459      -0.010       0.022\n",
       "3_2            0.0016      0.008      0.200      0.841      -0.014       0.018\n",
       "3_3           -0.0057      0.008     -0.684      0.494      -0.022       0.011\n",
       "3_4            0.0038      0.008      0.481      0.631      -0.012       0.020\n",
       "4_1           -0.0026      0.001     -2.237      0.025      -0.005      -0.000\n",
       "4_2            0.0005      0.001      0.423      0.672      -0.002       0.003\n",
       "4_3           -0.0027      0.001     -2.236      0.025      -0.005      -0.000\n",
       "4_4           -0.0023      0.001     -1.661      0.097      -0.005       0.000\n",
       "5_1            0.0002      0.004      0.060      0.953      -0.007       0.007\n",
       "5_2            0.0004      0.003      0.123      0.902      -0.006       0.007\n",
       "5_3           -0.0055      0.004     -1.555      0.120      -0.012       0.001\n",
       "5_4            0.0010      0.003      0.291      0.771      -0.006       0.008\n",
       "6_1           -0.0014      0.004     -0.342      0.732      -0.009       0.007\n",
       "6_2           -0.0007      0.004     -0.172      0.864      -0.008       0.007\n",
       "6_3            0.0065      0.004      1.556      0.120      -0.002       0.015\n",
       "6_4           -0.0040      0.004     -1.004      0.315      -0.012       0.004\n",
       "7_1            0.0047      0.008      0.574      0.566      -0.011       0.021\n",
       "7_2           -0.0054      0.009     -0.611      0.541      -0.023       0.012\n",
       "7_3            0.0038      0.008      0.486      0.627      -0.012       0.019\n",
       "7_4           -0.0013      0.007     -0.176      0.860      -0.015       0.013\n",
       "8_1           -0.0065      0.003     -1.865      0.062      -0.013       0.000\n",
       "8_2           -0.0046      0.004     -1.102      0.270      -0.013       0.004\n",
       "8_3            0.0082      0.003      2.430      0.015       0.002       0.015\n",
       "8_4           -0.0027      0.004     -0.680      0.496      -0.010       0.005\n",
       "ar.L1         -0.7692      0.032    -24.011      0.000      -0.832      -0.706\n",
       "ar.L2         -0.6443      0.042    -15.450      0.000      -0.726      -0.563\n",
       "ar.L3         -0.4673      0.044    -10.534      0.000      -0.554      -0.380\n",
       "ar.L4         -0.3058      0.042     -7.206      0.000      -0.389      -0.223\n",
       "ar.L5         -0.1566      0.034     -4.630      0.000      -0.223      -0.090\n",
       "sigma2      2.029e-06   8.72e-08     23.267      0.000    1.86e-06     2.2e-06\n",
       "===================================================================================\n",
       "Ljung-Box (L1) (Q):                   1.09   Jarque-Bera (JB):                21.91\n",
       "Prob(Q):                              0.30   Prob(JB):                         0.00\n",
       "Heteroskedasticity (H):               0.92   Skew:                             0.12\n",
       "Prob(H) (two-sided):                  0.48   Kurtosis:                         3.69\n",
       "===================================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
       "\"\"\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0022232342125417803"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.iloc[1001,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>0</th>\n",
=======
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>0</th>\n",
       "      <td>-13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.640015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.399963</td>\n",
=======
       "      <th>2003-01-02</th>\n",
       "      <td>-0.012478</td>\n",
       "      <td>0.031875</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>-0.112858</td>\n",
       "      <td>0.028072</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>-0.005716</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>0.004512</td>\n",
       "      <td>-0.000677</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>-0.027964</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>-0.043233</td>\n",
       "      <td>-0.005749</td>\n",
       "      <td>-0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>0.024685</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>0.085370</td>\n",
       "      <td>0.031986</td>\n",
       "      <td>-0.016625</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>-0.007154</td>\n",
       "      <td>-0.003759</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>-0.013479</td>\n",
       "      <td>0.022877</td>\n",
       "      <td>-0.005513</td>\n",
       "      <td>-0.006135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>0.009319</td>\n",
       "      <td>-0.016621</td>\n",
       "      <td>-0.021305</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>-0.024559</td>\n",
       "      <td>-0.031323</td>\n",
       "      <td>-0.005543</td>\n",
       "      <td>0.055556</td>\n",
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
<<<<<<< HEAD
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-10.129883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.470093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-3.039917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>15.479980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3.059937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0   -13.000000\n",
       "1    17.640015\n",
       "2     0.000000\n",
       "3    -1.309998\n",
       "4     5.399963\n",
       "..         ...\n",
       "995 -10.129883\n",
       "996  -0.470093\n",
       "997  -3.039917\n",
       "998  15.479980\n",
       "999   3.059937\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(AR.X))\n",
    "display(pd.DataFrame(AR.y))"
=======
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-26</th>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>-0.009381</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>-0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-27</th>\n",
       "      <td>0.006804</td>\n",
       "      <td>-0.006034</td>\n",
       "      <td>-0.011971</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>-0.004310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-30</th>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>-0.001884</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>-0.008658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-31</th>\n",
       "      <td>0.007021</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>-0.008929</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>-0.008734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-01</th>\n",
       "      <td>-0.003668</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.013673</td>\n",
       "      <td>0.036937</td>\n",
       "      <td>-0.048974</td>\n",
       "      <td>-0.074420</td>\n",
       "      <td>-0.003967</td>\n",
       "      <td>0.004405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1         2         3         4         5         6  \\\n",
       "Date                                                                     \n",
       "2003-01-02 -0.012478  0.031875  0.036945 -0.112858  0.028072  0.023364   \n",
       "2003-01-03  0.004512 -0.000677  0.001610 -0.027964  0.003065 -0.043233   \n",
       "2003-01-06  0.002597  0.019982  0.024685  0.009319  0.085370  0.031986   \n",
       "2003-01-07 -0.007154 -0.003759  0.007212  0.008832 -0.013479  0.022877   \n",
       "2003-01-08  0.009319 -0.016621 -0.021305  0.015917 -0.024559 -0.031323   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2006-10-26  0.004731  0.002388  0.009552 -0.009381  0.006105  0.006122   \n",
       "2006-10-27  0.006804 -0.006034 -0.011971  0.022727  0.003861  0.004127   \n",
       "2006-10-30 -0.000255 -0.000311  0.005594  0.037037 -0.001884  0.000790   \n",
       "2006-10-31  0.007021 -0.000477  0.001244 -0.008929  0.003696  0.004633   \n",
       "2006-11-01 -0.003668 -0.004115 -0.013673  0.036937 -0.048974 -0.074420   \n",
       "\n",
       "                   7         8  \n",
       "Date                            \n",
       "2003-01-02 -0.005716  0.000000  \n",
       "2003-01-03 -0.005749 -0.012195  \n",
       "2003-01-06 -0.016625  0.006173  \n",
       "2003-01-07 -0.005513 -0.006135  \n",
       "2003-01-08 -0.005543  0.055556  \n",
       "...              ...       ...  \n",
       "2006-10-26  0.006664 -0.008547  \n",
       "2006-10-27  0.006620 -0.004310  \n",
       "2006-10-30 -0.001315 -0.008658  \n",
       "2006-10-31 -0.003951 -0.008734  \n",
       "2006-11-01 -0.003967  0.004405  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.iloc[:1000,1:]"
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 154,
=======
   "execution_count": 35,
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(DATA.iloc[1000:,0], label = \"truth\", )\n",
    "plt.plot(forecasts, label = \"forecasts\")\n",
    "plt.legend()\n",
    "plt.show()"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-11-02</th>\n",
       "      <td>0.001025</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.007819</td>\n",
       "      <td>-0.018374</td>\n",
       "      <td>-0.012513</td>\n",
       "      <td>-0.003982</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-03</th>\n",
       "      <td>-0.007459</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.022767</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>-0.010378</td>\n",
       "      <td>-0.003998</td>\n",
       "      <td>0.017544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-06</th>\n",
       "      <td>-0.001608</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061606</td>\n",
       "      <td>0.065531</td>\n",
       "      <td>-0.011151</td>\n",
       "      <td>0.012931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-07</th>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>-0.006272</td>\n",
       "      <td>0.011971</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>-0.003608</td>\n",
       "      <td>-0.004255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-08</th>\n",
       "      <td>-0.002037</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>-0.030658</td>\n",
       "      <td>-0.004074</td>\n",
       "      <td>0.024612</td>\n",
       "      <td>-0.003622</td>\n",
       "      <td>0.004274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-26</th>\n",
       "      <td>-0.005975</td>\n",
       "      <td>-0.007381</td>\n",
       "      <td>-0.010670</td>\n",
       "      <td>0.025094</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.013072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-27</th>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>-0.106686</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.038710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-30</th>\n",
       "      <td>-0.013509</td>\n",
       "      <td>-0.013883</td>\n",
       "      <td>-0.015629</td>\n",
       "      <td>0.112883</td>\n",
       "      <td>-0.005498</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>-0.008267</td>\n",
       "      <td>-0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-31</th>\n",
       "      <td>0.011463</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>-0.002802</td>\n",
       "      <td>-0.042631</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>-0.007566</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.019355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-01</th>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.025438</td>\n",
       "      <td>0.029711</td>\n",
       "      <td>-0.082917</td>\n",
       "      <td>0.135446</td>\n",
       "      <td>0.043529</td>\n",
       "      <td>-0.004653</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1         2         3         4         5         6  \\\n",
       "Date                                                                     \n",
       "2006-11-02  0.001025 -0.001037 -0.000141 -0.007819 -0.018374 -0.012513   \n",
       "2006-11-03 -0.007459 -0.002704 -0.001384 -0.022767 -0.002686 -0.010378   \n",
       "2006-11-06 -0.001608  0.009971  0.015085  0.000000  0.061606  0.065531   \n",
       "2006-11-07  0.004932  0.004231  0.004197 -0.006272  0.011971  0.003045   \n",
       "2006-11-08 -0.002037  0.001626  0.003813 -0.030658 -0.004074  0.024612   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2010-08-26 -0.005975 -0.007381 -0.010670  0.025094  0.003301  0.003038   \n",
       "2010-08-27  0.004007  0.016508  0.016491 -0.106686  0.002046 -0.000322   \n",
       "2010-08-30 -0.013509 -0.013883 -0.015629  0.112883 -0.005498 -0.003095   \n",
       "2010-08-31  0.011463  0.000498 -0.002802 -0.042631  0.001817 -0.007566   \n",
       "2010-09-01  0.004659  0.025438  0.029711 -0.082917  0.135446  0.043529   \n",
       "\n",
       "                   7         8  \n",
       "Date                            \n",
       "2006-11-02 -0.003982  0.000000  \n",
       "2006-11-03 -0.003998  0.017544  \n",
       "2006-11-06 -0.011151  0.012931  \n",
       "2006-11-07 -0.003608 -0.004255  \n",
       "2006-11-08 -0.003622  0.004274  \n",
       "...              ...       ...  \n",
       "2010-08-26  0.000920  0.013072  \n",
       "2010-08-27  0.000919  0.038710  \n",
       "2010-08-30 -0.008267 -0.037267  \n",
       "2010-08-31 -0.004631 -0.019355  \n",
       "2010-09-01 -0.004653  0.026316  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.iloc[1000:2000,1:]"
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.11.3"
=======
   "version": "3.11.5"
>>>>>>> e253e2ad6c62a85006f30898ec95d453ec43abdb
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
